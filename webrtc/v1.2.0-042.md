# RTP 媒体api

## 目录

<!-- vim-markdown-toc GFM -->

- [Media Capture and Streams中的术语描述](#media-capture-and-streams中的术语描述)
- [回到RTP Media API](#回到rtp-media-api)
- [rescale or resample](#rescale-or-resample)

<!-- vim-markdown-toc -->

web app中的RTP media API是干嘛的？

使用这些api，可以从一个p2p连接中进行收发MediaStreamTracks

第二个问题，MediaStreamTrack是什么(rfc/spec的好处是术语都能找到具体描述)？

非本地媒体源的情况下，MediaStreamTrack对象表示一个MediaStream

第三个问题 MedisaStream是什么

[answer](https://www.w3.org/TR/mediacapture-streams/)

## Media Capture and Streams中的术语描述

MediaStream和MediaStreamTrack是MediaStream API最重要的两个概念。

MediaStreamTrack对象：表示一个用户agent的一个媒体源中一种类型的媒体。
eg：摄像头生成的视频媒体就是一个，摄像头生成的音频媒体也是一个。

MediaStream是一个容器，里面可以有多种MediaStreamTrack，通过这个容器，
这些媒体就可以被录制或渲染出来。

这就是流stream和轨道track的概念,一个stream可以有多个track，
一个stream的所有track在渲染时，都是同步的。同步不是强制要求。

ps：某些场合，track不同步也是非常适合的，
当track来至远端，且是rtc时(eg：webrtc)，不同更好一点。

轨道track可能包含多声道，eg：立体音/立体视频等

流stream有一个输入和一个输出表示：所有的track都公用输入输出。
stram的输出可以控制渲染。说白了，你stream里是什么，那么录制和渲染的就是什么。
一个stream的输出可以同时附加到多个输出中。

使用MediaStream()构造函数，可以构造一个新的MediaStream，
特别是可以基于已有的stream/track。
这样的话，之前stream的所有track都会加到新的stream中。如果是基于又有track构造，
那么可以达到这样的效果：一个stream的track来至多个不同的数据源。

stream/track都是可以拷贝的，只是拷贝后，她们的约束不一定一致，
这里的约束是针对媒体源的一些设置，好处是让不同的消费者用不同的约束来消费。
消费者就是从这些stream/track读数据的程序/组件。

## 回到RTP Media API

RTP Media API允许wep app通过p2p连接收发MediaStreamTrack。

在RTCPeerConnection中添加一个track时，会触发一个信号，
这个信号丢到peer后，就会触发peer对应的事件。

RTCPeerConnnection发送的轨道track，和peer接收的track轨道数，并不会是1:1的。
发送端的轨道id列表就没有和接收端的轨道id列表映射。
调用replaceTrack来改变RTCRtpSender发送的track轨道，
并不会触发接收端创建新的track轨道，接收端的RTCRtpReceiver只会有一个轨道track，
这个轨道就可能对应多个远端多个数据源(只不过同一时间只有一个数据源)。

同一个轨道track发送多次，可利用addTransceiver/replaceTrack来实现，
接收方会有多个接收者来接收，接收的每个轨道track都是独立的。

发送方的RTCRtpSender和接收方的RTCRtpReceiver是1:1对应的，
接收方接收的轨道数可能是10,实际上可能有3个轨道是重复发送的，
所以发送方的轨道数是7,这就和上面的"轨道数不是1:1"相呼应。

最后发送者和接收者的匹配，应该按照RTCRtpTransceiver.mid来匹配。

## rescale or resample

发送媒体时，为了符合sdp协商需求，可能会对媒体进行重新缩放/重采样。
按jsep3.6节，为了符合sdp约束，媒体只能进行下采样(我猜是缩小和丢失质量)。
不能造假数据来放大或增加质量。
另外除非是为了满足约束上的限制，媒体是不能进行裁剪或改变宽高比的。
不过___最近标准工作组在讨论修改这块的限制___

视频的重新缩放可能会导致有小数位的出现，这个标准只规定了视频宽高必须是整数，
至于宽高是0的场景，标准并未规定，这就看每个实现了。

这份标准还规定了，MediaStreamTrack，也就是轨道的编码和传输，都由RTCRtpSender管理，
对应的，接收和解码由RTCRtpReceiver管理，一个RTCRtpSender最多和一个track绑定，
接收端一个track也只能和一个RTCRtpReceiver绑定

MediaStreamTrack的编码和传输特征应该被远端创建的Track在一定程度上保留，
这些特征包括(视频的宽高/帧率，音频的音量/声道数/采样大小/采样率)。
也有部分场景下，发端和收端的特征是不一致的，例如断点和网络上资源的限制，
或者各个实现对RTCRtpSender的不同处理。

每个RTCPeerConnection对象都会有一个RTCRtpTransceiver列表，
这个RTCRtpTransceiver表示一对共享状态的发送者和接收者。
连接对象构造时，这个列表是空的，当构造RTCRtpSender和RTCRtpRecevier时，
也会构造一个RTCRtpTransceiver。

调用addTrack方法，可以为连接附加一个MediaStreamTrack轨道，
此时会隐式构造一个RTCRtpTransceiver;
调用addTransceiver方法，会显示构造一个RTCRtpTransceiver对象。
当一个包含新媒体级信息的远端sdp被接受时，也够构造RTCRtpTransceiver对象。
接受一个远端sdp，如果远端要发送媒体，那么在引用程序中，可通过track事件接收
MediaStreamTrack/RTCRtpRecevier。
